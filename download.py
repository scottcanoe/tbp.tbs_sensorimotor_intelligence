# Copyright 2025 Thousand Brains Project
#
# Copyright may exist in Contributors' modifications
# and/or contributions to the work.
#
# Use of this source code is governed by the MIT
# license that can be found in the LICENSE file or at
# https://opensource.org/licenses/MIT.
import argparse
import os
import shutil
import subprocess as sp
import sys
from pathlib import Path

description = """
Download and extract datasets used by `tbp.tbs_sensorimotor_intelligence`.

This script downloads datasets required to run experiments and/or plotting
scripts. It accepts one or more dataset names as arguments.

Usage:
    python download.py [dataset1] [dataset2] ...

Available datasets:
  ycb                     The YCB object dataset (~500 MB). Required for
                          running experiments using `tbp.monty`. See
                          https://www.ycbbenchmarks.com for details.

  monty.pretrained_models
                          Pretrained models used by `tbp.monty` in this
                          paper (3.4 GB).

  monty.results           Output generated by running core experiments in
                          the paper (3.2 MB).

  monty.visualizations    Results from experiments used for specific
                          figures (~850 MB).

  monty.view_finder_images
                          Intermediate output used to generate input data
                          for the ViT model (400 MB).

Notes:
  - Two environment variables determine where files are downloaded to.
    - `MONTY_DATA`: Path where the YCB dataset will be downloaded.
                    Default: `~/tbp/data`
    - `DMC_ROOT_DIR`: Path where all other datasets will be downloaded.
                      Default: `~/tbp/results/dmc`
  - If a requested dataset already exists, you will be prompted before it
    is overwritten.

"""

parser = argparse.ArgumentParser(
    description=description,
    formatter_class=argparse.RawDescriptionHelpFormatter,
)
parser.add_argument(
    "datasets",
    nargs="+",
    help="One or more datasets to download (e.g. monty.pretrained_models)",
)


DMC_ROOT_DIR = Path(os.environ.get("DMC_ROOT_DIR", "~/tbp/results/dmc")).expanduser()
MONTY_DATA_DIR = Path(os.environ.get("MONTY_DATA", "~/tbp/data")).expanduser()
DATASETS = {
    "monty.pretrained_models": {
        "url": "https://tbp-pretrained-models-public-c9c24aef2e49b897.s3.us-east-2.amazonaws.com/tbp.tbs_sensorimotor_intelligence/monty/pretrained_models.tar.gz",
        "destination.compressed": DMC_ROOT_DIR / "pretrained_models.tar.gz",
        "destination.uncompressed": DMC_ROOT_DIR / "pretrained_models",
    },
    "monty.results": {
        "url": "https://tbp-pretrained-models-public-c9c24aef2e49b897.s3.us-east-2.amazonaws.com/tbp.tbs_sensorimotor_intelligence/monty/results.tar.gz",
        "destination.compressed": DMC_ROOT_DIR / "results.tar.tgz",
        "destination.uncompressed": DMC_ROOT_DIR / "results",
    },
    "monty.visualizations": {
        "url": "https://tbp-pretrained-models-public-c9c24aef2e49b897.s3.us-east-2.amazonaws.com/tbp.tbs_sensorimotor_intelligence/monty/visualizations.tar.gz",
        "destination.compressed": DMC_ROOT_DIR / "visualizations.tar.tgz",
        "destination.uncompressed": DMC_ROOT_DIR / "visualizations",
    },
    "monty.view_finder_images": {
        "url": "https://tbp-pretrained-models-public-c9c24aef2e49b897.s3.us-east-2.amazonaws.com/tbp.tbs_sensorimotor_intelligence/monty/view_finder_images.tar.gz",
        "destination.compressed": DMC_ROOT_DIR / "view_finder_images.tar.tgz",
        "destination.uncompressed": DMC_ROOT_DIR / "view_finder_images",
    },
}


def confirm_overwrite(path: Path) -> bool:
    """Ask the user if it should overwrite an existing file.

    Args:
        path: An existing path.

    Returns:
        True if the user confirms overwrite, False otherwise.
    """
    overwrite = None
    while overwrite is None:
        overwrite = input(f"File {path} already exists. Overwrite? (y/[n]): ")
        overwrite = overwrite.lower().strip()
        if overwrite in ("y",):
            overwrite = True
        elif overwrite in ("n", ""):
            overwrite = False
        else:
            overwrite = None
    return overwrite


def download_dmc_dataset(dataset: str) -> None:
    """Download and extract one of our datasets.

    Args:
        dataset: The name of the dataset to download (e.g. "monty.pretrained_models").
    """
    dataset_info = DATASETS[dataset]

    # Check if the (uncompressed) destination already exists. If so, ask the user
    # if they want to overwrite it.
    if dataset_info["destination.uncompressed"].exists():
        overwrite = confirm_overwrite(dataset_info["destination.uncompressed"])
        if overwrite:
            # Delete the destination.
            if dataset_info["destination.uncompressed"].is_dir():
                shutil.rmtree(dataset_info["destination.uncompressed"])
            else:
                dataset_info["destination.uncompressed"].unlink()
        else:
            print(f"Skipping {dataset}.")
            return

    # Download the file.
    dataset_info["destination.compressed"].parent.mkdir(parents=True, exist_ok=True)
    command = [
        "curl",
        "-L",
        dataset_info["url"],
        "-o",
        dataset_info["destination.compressed"],
    ]
    sp.run(command)

    # Decompress the file.
    command = [
        "tar",
        "-xzf",
        dataset_info["destination.compressed"],
        "-C",
        dataset_info["destination.uncompressed"].parent,
    ]
    sp.run(command)

    # Delete the compressed file.
    dataset_info["destination.compressed"].unlink()


def download_ycb_dataset() -> None:
    """Download the YCB object dataset."""
    monty_data_dir = Path(os.environ.get("MONTY_DATA", "~/tbp/data")).expanduser()
    habitat_data_dir = monty_data_dir / "habitat"
    if habitat_data_dir.exists():
        overwrite = confirm_overwrite(habitat_data_dir)
        if overwrite:
            shutil.rmtree(habitat_data_dir)
        else:
            print("Skipping habitat data download.")
            return

    command = [
        "python",
        "-m",
        "habitat_sim.utils.datasets_download",
        "--uids",
        "ycb",
        "--data-path",
        habitat_data_dir,
    ]
    sp.run(command)


def main() -> None:
    """Download and extract datasets specified via command line arguments.

    This function serves as the entry point for the download script.
    """
    args = parser.parse_args()

    datasets = list(set(args.datasets))

    # Validate the arguments.
    for name in datasets:
        if name not in DATASETS:
            print(f"Invalid dataset name '{name}'.")
            sys.exit(1)

    # Download the YCB dataset if requested.
    if "ycb" in datasets:
        datasets.remove("ycb")
        download_ycb_dataset()

    # Download and extract one of our datasets.
    for name in datasets:
        download_dmc_dataset(name)


if __name__ == "__main__":
    main()
