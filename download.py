# Copyright 2025 Thousand Brains Project
#
# Copyright may exist in Contributors' modifications
# and/or contributions to the work.
#
# Use of this source code is governed by the MIT
# license that can be found in the LICENSE file or at
# https://opensource.org/licenses/MIT.
import argparse
import os
import shutil
import subprocess as sp
import sys
from pathlib import Path

TESTING = False
description = """
Download and extract datasets used by `tbp.tbs_sensorimotor_intelligence`.

This script downloads datasets required to run experiments and/or plotting scripts.
It accepts one or more dataset names as arguments.

Usage:
    python download.py [dataset1] [dataset2] ...

Available datasets:
  ycb                     The YCB object dataset (~500 MB). Required for running
                          experiments using `tbp.monty`. See
                          https://www.ycbbenchmarks.com for details.

  monty.pretrained_models
                          Pretrained models used by `tbp.monty` in this paper (3.4 GB).

  monty.results           Output generated by running core experiments in the paper (3.2 MB).

  monty.visualizations    Results from experiments used for specific figures (~850 MB).

  monty.view_finder_images
                          Intermediate output used to generate input data for the ViT model (400 MB).

Notes:
  - Two environment variables determine where files are downloaded to.
    - `MONTY_DATA`: Path where the YCB dataset will be downloaded.
                    Default: `~/tbp/data`
    - `DMC_ROOT_DIR`: Path where all other datasets will be downloaded.
                      Default: `~/tbp/results/dmc`
  - If a requested dataset already exists, you will be prompted before it is
    overwritten.

"""

parser = argparse.ArgumentParser(
    description=description,
    formatter_class=argparse.RawDescriptionHelpFormatter,
)
parser.add_argument(
    "file_ids",
    nargs="+",
    help="One or more file IDs to download (e.g. monty.pretrained_models",
)


DMC_ROOT_DIR = Path(os.environ.get("DMC_ROOT_DIR", "~/tbp/results/dmc")).expanduser()
MONTY_DATA_DIR = Path(os.environ.get("MONTY_DATA", "~/tbp/data")).expanduser()
FILE_INFO = {
    "monty.pretrained_models": {
        "url": "https://tbp-pretrained-models-public-c9c24aef2e49b897.s3.us-east-2.amazonaws.com/tbp.tbs_sensorimotor_intelligence/monty/pretrained_models.tar.gz",
        "destination.compressed": DMC_ROOT_DIR / "pretrained_models.tar.gz",
        "destination.uncompressed": DMC_ROOT_DIR / "pretrained_models",
    },
    "monty.results": {
        "url": "",
        "destination.compressed": DMC_ROOT_DIR / "results.tar.tgz",
        "destination.uncompressed": DMC_ROOT_DIR / "results",
    },
    "monty.visualizations": {
        "url": "",
        "destination.compressed": DMC_ROOT_DIR / "visualizations.tar.tgz",
        "destination.uncompressed": DMC_ROOT_DIR / "visualizations",
    },
    "monty.view_finder_images": {
        "url": "",
        "destination.compressed": DMC_ROOT_DIR / "view_finder_images.tar.tgz",
        "destination.uncompressed": DMC_ROOT_DIR / "view_finder_images",
    },
}


def confirm_overwrite(path: Path) -> bool:
    """Ask the user if it should overwrite an existing file.

    Args:
        file_id: The id of the file to check (e.g. "monty.pretrained_models")

    Returns:
        True if the user confirms overwrite, False otherwise.
    """
    overwrite = None
    while overwrite is None:
        overwrite = input(f"File {path} already exists. Overwrite? (y/[n]): ")
        overwrite = overwrite.lower().strip()
        if overwrite in ("y",):
            overwrite = True
        elif overwrite in ("n", ""):
            overwrite = False
        else:
            overwrite = None
    return overwrite


def download_file(file_id: str) -> None:
    """Download and extract a dataset.

    Args:
        file_id: The id of the file to download (e.g. "monty.pretrained_models").
    """
    info = FILE_INFO[file_id]

    # Check if the (uncompressed) destination already exists. If so, ask the user
    # if they want to overwrite it.
    if info["destination.uncompressed"].exists():
        overwrite = confirm_overwrite(info["destination.uncompressed"])
        if overwrite:
            # Delete the destination.
            if info["destination.uncompressed"].is_dir():
                shutil.rmtree(info["destination.uncompressed"])
            else:
                info["destination.uncompressed"].unlink()
        else:
            print(f"Skipping {file_id}.")
            return

    # Download the file.
    info["destination.compressed"].parent.mkdir(parents=True, exist_ok=True)
    command = [
        "curl",
        "-L",
        info["url"],
        "-o",
        info["destination.compressed"],
    ]
    sp.run(command)

    # Decompress the file.
    command = [
        "tar",
        "-xzf",
        info["destination.compressed"],
        "-C",
        info["destination.uncompressed"].parent,
    ]
    sp.run(command)

    # Delete the compressed file.
    info["destination.compressed"].unlink()


def download_habitat() -> None:
    """Download the YCB object dataset."""
    monty_data_dir = Path(os.environ.get("MONTY_DATA", "~/tbp/data")).expanduser()
    habitat_data_dir = monty_data_dir / "habitat"
    if habitat_data_dir.exists():
        overwrite = confirm_overwrite(habitat_data_dir)
        if overwrite:
            shutil.rmtree(habitat_data_dir)
        else:
            print("Skipping habitat data download.")
            return

    command = [
        "python",
        "-m",
        "habitat_sim.utils.datasets_download",
        "--uids",
        "ycb",
        "--data-path",
        habitat_data_dir,
    ]
    sp.run(command)


def main() -> None:
    """Download and extract datasets."""
    args = parser.parse_args()

    to_download = list(args.file_ids)
    to_download = []
    for file_id in args.file_ids:
        if file_id in FILE_GROUPS:
            to_download.extend(FILE_GROUPS[file_id])
        else:
            to_download.append(file_id)

    to_download = list(sorted(set(to_download)))

    # Check if we need to download habitat data. It is handled separately.
    if "monty.habitat" in to_download:
        to_download.remove("monty.habitat")
        download_habitat()

    # Validate the file IDs.
    for file_id in to_download:
        if file_id not in FILE_INFO:
            print(f"Invalid file_id '{file_id}'.")
            sys.exit(1)

    # Download the files.
    for file_id in to_download:
        download_file(file_id)


if __name__ == "__main__":
    main()
